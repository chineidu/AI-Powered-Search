{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.26.0\n",
      "\n",
      "numpy    : 1.26.4\n",
      "pandas   : 2.2.2\n",
      "polars   : 1.0.0\n",
      "torch    : 2.2.2\n",
      "lightning: 2.3.2\n",
      "\n",
      "conda environment: ai_search\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,polars,torch,lightning --conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'happy': 1, 'i': 2, 'today': 3, 'very': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text: list[str] = [\"i\", \"am\", \"very\", \"happy\", \"today\"]\n",
    "vocab_set: set = sorted(set(text))\n",
    "vocab: dict[str, int] = {word: idx for idx, word in enumerate(vocab_set, start=0)}\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'very', 'happy', 'today']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern: str = r'([,.?_!\"()\\']|--|\\s)'\n",
    "result: list[str] = re.split(pattern=pattern, string=\" \".join(text))\n",
    "result = [x for x in result if x.strip()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def tokenize(doc: list[str]) -> list[str]:\n",
    "    # Pattern for separating tokens\n",
    "    pattern: str = r'([,.?_!\"()\\':]|\\s)'\n",
    "    # Lowercase all words\n",
    "    doc = [word.lower() for word in doc]\n",
    "    tok_doc: list[str] = re.split(pattern=pattern, string=\" \".join(doc))\n",
    "    # Remove whitespaces and empty strings\n",
    "    tok_doc = [word for word in tok_doc if word.strip()]\n",
    "    return tok_doc\n",
    "\n",
    "\n",
    "def generate_vocab(doc: list[list[str]], drop_punct: bool = True) -> dict[str, int]:\n",
    "\n",
    "    assert all(\n",
    "        [True if isinstance(row, list) else False for row in doc]\n",
    "    ), \"Not all elements are lists\"\n",
    "\n",
    "    flattened_doc: list[str] = [word.lower() for row in doc for word in row]\n",
    "    tok_doc: list[str] = tokenize(flattened_doc)\n",
    "    if drop_punct:\n",
    "        tok_doc = [word for word in tok_doc if word not in string.punctuation]\n",
    "    tok_doc = sorted(set(tok_doc))\n",
    "\n",
    "    vocab: dict[str, int] = {word: idx for idx, word in enumerate(tok_doc, start=0)}\n",
    "    print(f\"Vocab size: {len(vocab)}\")\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def encode(doc: list[list[str]], vocab: dict[str, int]) -> list[int]:\n",
    "    arr: np.ndarray = np.zeros((1, len(vocab)), dtype=int)\n",
    "    for row in doc:\n",
    "        for word in tokenize(row):\n",
    "            if word in vocab:\n",
    "                arr[0, vocab[word]] = 1  # change!\n",
    "    return arr\n",
    "\n",
    "\n",
    "def encode_n_create_df(doc: list[list[str]], vocab: dict[str, int]) -> pl.DataFrame:\n",
    "    df: pl.DataFrame = pl.DataFrame(encode(doc=doc, vocab=vocab))\n",
    "    df.columns = list(vocab.keys())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 6\n",
      "vocab = {'about': 0, 'hey': 1, 'me': 2, 'neidu': 3, 'something': 4, 'tell': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc: list[list[str]] = [[\"Hey! Tell me something about neidu.\"]]\n",
    "vocab: dict[str, int] = generate_vocab(doc=doc, drop_punct=True)\n",
    "print(f\"{vocab = }\")\n",
    "\n",
    "encode(doc=[[\"tell Tell\"]], vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>about</th><th>hey</th><th>me</th><th>neidu</th><th>something</th><th>tell</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "┌───────┬─────┬─────┬───────┬───────────┬──────┐\n",
       "│ about ┆ hey ┆ me  ┆ neidu ┆ something ┆ tell │\n",
       "│ ---   ┆ --- ┆ --- ┆ ---   ┆ ---       ┆ ---  │\n",
       "│ i64   ┆ i64 ┆ i64 ┆ i64   ┆ i64       ┆ i64  │\n",
       "╞═══════╪═════╪═════╪═══════╪═══════════╪══════╡\n",
       "│ 1     ┆ 0   ┆ 0   ┆ 0     ┆ 0         ┆ 1    │\n",
       "└───────┴─────┴─────┴───────┴───────────┴──────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_n_create_df(doc=[[\"about Tell\"]], vocab=vocab)\n",
    "\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "#### [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity#:~:text=Cosine%20similarity%20is%20the%20cosine,but%20only%20on%20their%20angle.)\n",
    "\n",
    "- Cosine similarity is the cosine of the angle between the vectors; that is, it is the dot product of the vectors divided by the product of their lengths.\n",
    "- It follows that the cosine similarity does not depend on the magnitudes of the vectors, but only on their angle.\n",
    "\n",
    "$$cosSimilarity = cos(\\theta) = \\frac{A . B}{||A||.||B||}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def cosine_similarity(vector1: np.ndarray, vector2: np.ndarray) -> float:\n",
    "    return np.dot(vector1, vector2) / (norm(vector1) * norm(vector2))\n",
    "\n",
    "\n",
    "def check_equality(vector_1: np.ndarray, vector_2: np.ndarray) -> bool:\n",
    "    result: bool = np.array_equal(vector_1, vector_2)\n",
    "    print(f\"{result = }\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746318461970762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vector1=np.array([1, 2, 3]), vector2=np.array([4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 48\n",
      "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "doc1: list[str] = [\n",
    "    (\n",
    "        \"Lynn: ham and cheese sandwich, chocolate cookie, ice water. \"\n",
    "        \"Brian: turkey avocado sandwich, plain potato chips, apple juice \"\n",
    "        \"Mohammed: grilled chicken salad, fruit cup, lemonade \"\n",
    "    )\n",
    "]\n",
    "\n",
    "doc2: list[str] = [\n",
    "    (\n",
    "        \"Orchard Farms apple juice is premium, organic apple juice made from the \"\n",
    "        \"freshest apples, never from concentrate. Its juice has received the \"\n",
    "        \"regional award for best apple juice three years in a row. \"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "doc: list[list[str]] = [doc1, doc2]\n",
    "vocab: dict[str, int] = generate_vocab(doc=doc)\n",
    "\n",
    "query: list[list[str]] = [[\" apple juice\"]]\n",
    "query_vector: np.ndarray = encode(doc=query, vocab=vocab)\n",
    "doc1_vector: np.ndarray = encode(doc=[doc1], vocab=vocab)\n",
    "doc2_vector: np.ndarray = encode(doc=[doc2], vocab=vocab)\n",
    "\n",
    "print(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'and'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'apple'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'apples'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'avocado'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'award'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'best'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'brian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cheese'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chicken'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chips'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'chocolate'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'concentrate'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cookie'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'cup'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'farms'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'for'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'freshest'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'from'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fruit'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'grilled'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ham'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'has'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ice'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'in'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'its'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'juice'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lemonade'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lynn'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'made'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'mohammed'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'never'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'orchard'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'organic'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'plain'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'potato'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'premium'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'received'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'regional'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'row'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'salad'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'sandwich'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'the'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'three'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'turkey'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'water'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'years'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'a'\u001b[0m,\n",
       "    \u001b[32m'and'\u001b[0m,\n",
       "    \u001b[32m'apple'\u001b[0m,\n",
       "    \u001b[32m'apples'\u001b[0m,\n",
       "    \u001b[32m'avocado'\u001b[0m,\n",
       "    \u001b[32m'award'\u001b[0m,\n",
       "    \u001b[32m'best'\u001b[0m,\n",
       "    \u001b[32m'brian'\u001b[0m,\n",
       "    \u001b[32m'cheese'\u001b[0m,\n",
       "    \u001b[32m'chicken'\u001b[0m,\n",
       "    \u001b[32m'chips'\u001b[0m,\n",
       "    \u001b[32m'chocolate'\u001b[0m,\n",
       "    \u001b[32m'concentrate'\u001b[0m,\n",
       "    \u001b[32m'cookie'\u001b[0m,\n",
       "    \u001b[32m'cup'\u001b[0m,\n",
       "    \u001b[32m'farms'\u001b[0m,\n",
       "    \u001b[32m'for'\u001b[0m,\n",
       "    \u001b[32m'freshest'\u001b[0m,\n",
       "    \u001b[32m'from'\u001b[0m,\n",
       "    \u001b[32m'fruit'\u001b[0m,\n",
       "    \u001b[32m'grilled'\u001b[0m,\n",
       "    \u001b[32m'ham'\u001b[0m,\n",
       "    \u001b[32m'has'\u001b[0m,\n",
       "    \u001b[32m'ice'\u001b[0m,\n",
       "    \u001b[32m'in'\u001b[0m,\n",
       "    \u001b[32m'is'\u001b[0m,\n",
       "    \u001b[32m'its'\u001b[0m,\n",
       "    \u001b[32m'juice'\u001b[0m,\n",
       "    \u001b[32m'lemonade'\u001b[0m,\n",
       "    \u001b[32m'lynn'\u001b[0m,\n",
       "    \u001b[32m'made'\u001b[0m,\n",
       "    \u001b[32m'mohammed'\u001b[0m,\n",
       "    \u001b[32m'never'\u001b[0m,\n",
       "    \u001b[32m'orchard'\u001b[0m,\n",
       "    \u001b[32m'organic'\u001b[0m,\n",
       "    \u001b[32m'plain'\u001b[0m,\n",
       "    \u001b[32m'potato'\u001b[0m,\n",
       "    \u001b[32m'premium'\u001b[0m,\n",
       "    \u001b[32m'received'\u001b[0m,\n",
       "    \u001b[32m'regional'\u001b[0m,\n",
       "    \u001b[32m'row'\u001b[0m,\n",
       "    \u001b[32m'salad'\u001b[0m,\n",
       "    \u001b[32m'sandwich'\u001b[0m,\n",
       "    \u001b[32m'the'\u001b[0m,\n",
       "    \u001b[32m'three'\u001b[0m,\n",
       "    \u001b[32m'turkey'\u001b[0m,\n",
       "    \u001b[32m'water'\u001b[0m,\n",
       "    \u001b[32m'years'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(list(vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2886751345948129, 0.2773500981126146)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1_score = cosine_similarity(query_vector.squeeze(), doc1_vector.squeeze())\n",
    "doc2_score = cosine_similarity(query_vector.squeeze(), doc2_vector.squeeze())\n",
    "\n",
    "doc1_score, doc2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lynn: ham and cheese sandwich, chocolate cookie, ice water. Brian: turkey avocado sandwich, plain potato chips, apple juice Mohammed: grilled chicken salad, fruit cup, lemonade ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 48)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>a</th><th>and</th><th>apple</th><th>apples</th><th>avocado</th><th>award</th><th>best</th><th>brian</th><th>cheese</th><th>chicken</th><th>chips</th><th>chocolate</th><th>concentrate</th><th>cookie</th><th>cup</th><th>farms</th><th>for</th><th>freshest</th><th>from</th><th>fruit</th><th>grilled</th><th>ham</th><th>has</th><th>ice</th><th>in</th><th>is</th><th>its</th><th>juice</th><th>lemonade</th><th>lynn</th><th>made</th><th>mohammed</th><th>never</th><th>orchard</th><th>organic</th><th>plain</th><th>potato</th><th>premium</th><th>received</th><th>regional</th><th>row</th><th>salad</th><th>sandwich</th><th>the</th><th>three</th><th>turkey</th><th>water</th><th>years</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 48)\n",
       "┌─────┬─────┬───────┬────────┬───┬───────┬────────┬───────┬───────┐\n",
       "│ a   ┆ and ┆ apple ┆ apples ┆ … ┆ three ┆ turkey ┆ water ┆ years │\n",
       "│ --- ┆ --- ┆ ---   ┆ ---    ┆   ┆ ---   ┆ ---    ┆ ---   ┆ ---   │\n",
       "│ i64 ┆ i64 ┆ i64   ┆ i64    ┆   ┆ i64   ┆ i64    ┆ i64   ┆ i64   │\n",
       "╞═════╪═════╪═══════╪════════╪═══╪═══════╪════════╪═══════╪═══════╡\n",
       "│ 0   ┆ 1   ┆ 1     ┆ 0      ┆ … ┆ 0     ┆ 1      ┆ 1     ┆ 0     │\n",
       "└─────┴─────┴───────┴────────┴───┴───────┴────────┴───────┴───────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_n_create_df(doc=[doc1], vocab=vocab)\n",
    "# encode(doc=[doc1], vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 48)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>a</th><th>and</th><th>apple</th><th>apples</th><th>avocado</th><th>award</th><th>best</th><th>brian</th><th>cheese</th><th>chicken</th><th>chips</th><th>chocolate</th><th>concentrate</th><th>cookie</th><th>cup</th><th>farms</th><th>for</th><th>freshest</th><th>from</th><th>fruit</th><th>grilled</th><th>ham</th><th>has</th><th>ice</th><th>in</th><th>is</th><th>its</th><th>juice</th><th>lemonade</th><th>lynn</th><th>made</th><th>mohammed</th><th>never</th><th>orchard</th><th>organic</th><th>plain</th><th>potato</th><th>premium</th><th>received</th><th>regional</th><th>row</th><th>salad</th><th>sandwich</th><th>the</th><th>three</th><th>turkey</th><th>water</th><th>years</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 48)\n",
       "┌─────┬─────┬───────┬────────┬───┬───────┬────────┬───────┬───────┐\n",
       "│ a   ┆ and ┆ apple ┆ apples ┆ … ┆ three ┆ turkey ┆ water ┆ years │\n",
       "│ --- ┆ --- ┆ ---   ┆ ---    ┆   ┆ ---   ┆ ---    ┆ ---   ┆ ---   │\n",
       "│ i64 ┆ i64 ┆ i64   ┆ i64    ┆   ┆ i64   ┆ i64    ┆ i64   ┆ i64   │\n",
       "╞═════╪═════╪═══════╪════════╪═══╪═══════╪════════╪═══════╪═══════╡\n",
       "│ 1   ┆ 0   ┆ 1     ┆ 1      ┆ … ┆ 1     ┆ 0      ┆ 0     ┆ 1     │\n",
       "└─────┴─────┴───────┴────────┴───┴───────┴────────┴───────┴───────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_n_create_df(doc=[doc2], vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = True\n",
      "result = False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_equality(doc1_vector.squeeze(), doc1_vector.squeeze())\n",
    "check_equality(doc1_vector.squeeze(), doc2_vector.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311 (ai_search)",
   "language": "python",
   "name": "ai_search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
